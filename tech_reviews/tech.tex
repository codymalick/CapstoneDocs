\documentclass[10pt,letterpaper,onecolumn,draftclsnofoot]{IEEEtran}
\usepackage[margin=0.75in]{geometry}
\usepackage{listings}
\usepackage{color}
\usepackage{longtable}
\usepackage{graphicx}
\usepackage{float}
\usepackage{tabu}
\usepackage{enumitem}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\graphicspath{{../images/}}

\lstset{frame=tb,
language=C,
columns=flexible,
numberstyle=\tiny\color{gray},
keywordstyle=\color{blue},
commentstyle=\color{dkgreen},
stringstyle=\color{mauve},
breaklines=true,
breakatwhitespace=true,
tabsize=4,
showstringspaces=false
}

\setlength{\parindent}{0cm}

\begin{document}
\begin{titlepage}
	\title{CS 461 - Fall 2016 - Technology Review}
	\author{Matthew Johnson}
	\date{\today}
	\maketitle
	\vspace{4cm}
	\begin{abstract}
		\noindent This document explores nine components of the software
		defined network that will be implemented by the Cloud
		Orchestration Networking Project sponsored by the Intel
		Corporation. For each component of the system, three separate
		technologies are evaluated and compared. Finally, a technology
		is decided upon for every component.
	\end{abstract}

\end{titlepage}
\tableofcontents
\clearpage

\section{Introduction}

The nine components of the software defined network we are implementing are
defined in this document. For each component three technologies are evaluated
and compared. We select the technology we will be using for that component
based on criteria we have defined and explored.

The nine components of our system are:

\begin{description}[leftmargin=12em,style=nextline]
	\item[Programming Languages]
		The language our solution will be implemented in. Authored by
		Matthew Johnson.
	\item[Logging]
		The logging library our project will use to record events.
		Authored by Matthew Johnson.
	\item[Functional Testing Framework]
		The testing framework used to ensure functionality of our
		network implementation. Authored by Matthew Johnson.
	\item[Packet Level Protocols]
		The protocol for the creation and forwarding of packets.
		Authored by Cody Malick.
	\item[Switch Implementation]
		The software implementation type of a networking switch.
		Authored by Cody Malick.
	\item[Bridge Implementation]
		The software implementation type of a networking bridge.
		Authored by Cody Malick.
	\item[CNCI Implementation]
		The software implementation of the control nodes. Authored by
		Garrett Smith.
	\item[Compute Node Implementation]
		The software implementation of the compute nodes. Authored by
		Garrett Smith.
	\item[Performance Testing Framework]
		The testing framework used to measure performance of our network
		implementation. Authored by Garrett Smith.
\end{description}

\section{Programming Languages}

At the highest level, a main component of our software defined network
implementation is the programming language it is written in. This is an
important decision to make early in our design, as it affects all choices that
follow.

\subsection{Options}

\subsubsection{Go}

Our first choice is the Go programming language. This is naturally the strongest
choice as the rest of the Ciao infrastructure is written in Go. It would require
a very strong argument to create a separate networking mode in another language.
While technically possible, it would require a great deal of work to make the
different pieces compatible with each other.

\subsubsection{C}

Other than interaction with the rest of the Ciao project, C is another natural
choice. C has been around for decades, and has the capability to do nearly every
computational and networking task. The libraries are extensive and available and
the language is fast.

\subsubsection{Python}

Python is a choice here simply because of its ease of use. Python is very
expressive and has nice libraries that abstract away the complicated details of
software defined networking. The main downfalls of Python, however, are its
reduced speed and space efficiency compared to Go and C. A result of writing a
cloud orchestrator in Python is exemplified in the extremely complicated and
slow Openstack project~\cite{uglyopenstack}.

\subsection{Goals for use in design}

As stated, the choice of programming language will affect all aspects of our
design for this project, from code structure to networking libraries and module
design. This choice will easily have the largest impact on our project.

\subsection{Criteria being evaluated}

Important criteria to consider is the availability of necessary libraries and of
the language and its dependencies itself, the inherent speed of the language to
be used, the security features the language offers, the concurrency
capabilities, and the overall ease of use.

\subsubsection{Availability}

The most available language in terms of libraries and the language itself
(regarding its standard libraries) is obviously C because of how ubiquitous it
is, how universally available it is, and how extensive its standard libraries
are~\cite{SOC}.

Close behind C in availability is Python. Python is nearly as available as C is
because of how popular it has become in the last ten years~\cite{PYPL}. Python
has many libraries that provide simple abstractions to networking
functionalities.

Of all these languages, Go is the least available as it is the youngest and
least popular of the three. Go is not normally available by default on most
operating systems and must be installed by the user. Go does, however, have
available libraries that make it very easy to implement networking, as is
evidenced by the extent to which they are used in the Ciao project
currently~\cite{ciao}.

The following figure demonstrates the popularity of C, Go, and Python in the
United States in the last ten years.

\begin{figure}[H]
	\begin{center}
		\makebox[\textwidth]{\includegraphics[width=10cm]{pythoncgo.eps}}
		\caption{Python, C, and Go popularity in the US~\cite{PYPL}}
	\end{center}
\end{figure}

\subsubsection{Speed and Space Efficiency}

One benefit of lower-level languages like Go and C is how they treat their
variables. Go and C treat variables differently than some languages such as
Python, which create overhead in order to track type information, and Java,
which converts small ints to Integer class instances when placing them in a
list. An example of this is in the representations of the same value in Go,
Python, and C~\cite{davecheney}:

\begin{lstlisting}
var gocon int32 = 2014              // Go:      4 bytes
uint32_t gocon = 2014;              // C:       4 bytes
gocon = 2014                        #  Python: 24 bytes
\end{lstlisting}

Go performs comparably to C with regard to speed, as well~\cite{benchmarks},
which is considerable since C is often the standard for fast programming
languages. Compared to Python, as would be expected, Go and C can perform up to
45 times faster depending on the workload~\cite{benchmarks}.

\subsubsection{Concurrency}

Concurrency is a key consideration for programming languages when implementing a
software defined network. All operations must happen quickly and in parallel and
must scale effortlessly. Therefore, it is necessary that all operations run in
their own individual threads.

C has an extensive and established framework for parallel computing by utilizing
pthreads. Mutexes can help the programmer protect against race conditions in
their code, but the responsibility is up to the programmer to make their
software thread-safe.

Python has similar tools as C, but the parallelization is handled by a global
interpreter lock (GIL). The GIL is a "mutex that prevents multiple native
threads from executing Python bytecodes at once." GIL is necessary in python
because the underlying C code that implements python is not thread-safe. The GIL
"prevents multithreaded CPython programs from taking full advantage of
multiprocessor systems in certain situations"~\cite{GIL}.

Go, on the other hand, combines the power of C and the ease of use and
lock-handling of Python. You can use goroutines (functions that are capable of
running concurrently with other functions) to create concurrency. Utilization of
goroutines and other builtin language functionalities make concurrency very easy
and lightweight in Go. An example from golang-book.com demonstrates how simple
and lightweight threads in Go can actually be~\cite{goroutines}:

\begin{lstlisting}
package main

import "fmt"

func f(n int) {
	for i := 0; i < 10; i++ {
		fmt.Println(n, ":", i)
	}
}

func main() {
	go f(0)
	var input string
	fmt.Scanln(&input)
}
\end{lstlisting}

\subsubsection{Ease of use}

Python is by far the easiest to learn, use, and read. It focuses on
"readability, coherence, and software quality" and is recognized by many to be
extremely easy to use~\cite{learningpython}.

C, being the oldest and lowest-level language of the three, is not a simple
language to work with. Many things that are normally abstracted away in other
languages are required to be programmed explicitly by the programmer. String
manipulation is especially difficult in C.

Go is easier to learn than C and makes many improvements in terms of ease of
use. It was even designed this way. Go was designed to make programming
efficient in large-scale software development across teams with varying levels
of experience and skill. It was designed with "built-in concurrency and garbage
collection" and includes "rigorous dependency management."~\cite{godesign}.
These features are important for the work required by this project.

Another important note is that the rest of Ciao is written in Go, and while
possible to create interfaces from C or Python for Go, it would be very
difficult. Another option would be to re-implement Ciao in another language,
which is so difficult and time consuming that it cannot even be considered as an
option. With this consideration, Go is the clear winner in terms of ease of use.

\subsection{Direct Comparison}

\begin{center}
	\begin{tabular}{| l | l | l | l | l | l |}
		\hline
		Language & Availability & Efficiency & Concurrency & Ease of use
		\\ \hline
		Go     & 3 & 1 & 1 & 1 \\ \hline
		C      & 1 & 2 & 2 & 3 \\ \hline
		Python & 2 & 3 & 3 & 2 \\ \hline
	\end{tabular}
\end{center}

\subsection{Selection}

Based on the criteria explored above, the Go programming language is the
language we are selecting to implement our solution in. The remainder of the
technical review will be based on the assumption that we will be implementing
our solution in Go.

\section{Logging}

The logging libraries available for Go are almost innumerable, and most are very
similar to each other. It is important that the library is fast, easy to use,
and lightweight. Ciao currently uses the 'glog' standard logging library, but
due to the simplicity of logging it is feasible to choose another option.

\subsection{Options}

\subsubsection{Zap Logger}

Zap is a go logger that advertises "blazing fast, structured, leveled logging in
Go. According to benchmarks against other common logging libraries, Zap is
indeed fast and lightweight in terms of management. There are major concerns
here, however, including the overall size of the package along with its
dependencies and the fact that it is in its beta phase~\cite{zap}.

\subsubsection{Standard 'log' Library}

The log library is standard in Go, and therefore very lightweight with no
external dependencies. It is also simple to use with very many examples
available~\cite{log}. It has less functionality than the zap logger, but we have
very simple requirements.

\subsubsection{Standard 'glog' Library}

The glog library is very similar to the log library but adds a few features,
like an improved leveled-logging functionality~\cite{glog}. The main benefit
here is that glog is used by the rest of the Ciao project, and is therefore
trivial to setup and use in the networking portion~\cite{ciao}.

\subsection{Goals for use in design}

Our goal for the logging module we select is to record important events and
failures for debugging and functional testing.

\subsection{Criteria being evaluated}

\subsubsection{Speed}

As far as speed is concerned, the Zap logger appears to be the fastest of the
options we are exploring, according to benchmarks~\cite{zap}. Glog and log
appear to be very similar, but glog makes a significant efficiency improvement
by binding methods to booleans. This makes it possible to use glog "without
paying the expense of evaluating the arguments to the log"~\cite{glog}.

\subsubsection{Package Size}

It is also important to consider the size of the dependency we are adding to
Ciao. Zap, unfortunately, is a large package that is not already available in
the project.

The log library, being part of the standard library, has no effective size since
it is included with the language dependency.

The glog package, as an external dependency, would normally lose outright in
this category. However, the reset of the Ciao project already uses glog, so
using it in our portion would not add a dependency to Ciao that does not already
exist.

\subsubsection{Ease of Use}

Logging libraries are typically easy to use, and these three options are no
exception. Zap is perhaps the most complicated to setup and use as it requires a
structured log statement~\cite{zap}:

\begin{lstlisting}
logger.Info("Failed to fetch URL.",
	zap.String("url", url),
	zap.Int("attempt", tryNum),
	zap.Duration("backoff", sleepFor),
)
\end{lstlisting}

The standard log library is much simpler. An example of logging a statement in
log~\cite{log}:

\begin{lstlisting}
logger.Print("Hello, log file!")
\end{lstlisting}

The glog library is also very simpler, but provides the option of leveled logs.
The following is an example of logging an info and fatal statement, each in a
single line~\cite{glog}:

\begin{lstlisting}
glog.Info("Prepare to repel boarders")
glog.Fatalf("Initialization failed: %s", err)
\end{lstlisting}

\subsection{Direct Comparison}

\begin{center}
	\begin{tabular}{| l | l | l | l |}
		\hline
		Logging library & Speed & Package Size & Ease of Use
		\\ \hline
		log  & 3 & 1 & 2 \\ \hline
		glog & 2 & 2 & 1 \\ \hline
		zap  & 1 & 3 & 3 \\ \hline
	\end{tabular}
\end{center}

\subsection{Selection}

Based on our evaluation of log, glog, and zap, glog comes out on top by a very
small margin. The two simple packages, glog and log, were very close in every
category, and it basically came down to the fact that glog is currently in use
by ciao. We will be using glog for logging events in our portion of the project.

\section{Functional Testing Frameworks}

There are several testing frameworks available for Go. These range from the
basic and simple 'testing' library to the more complicated and in-depth GoConvey
and Ginkgo frameworks. Depending on our choice here, we could either add too
much extraneous work getting a testing framework setup, or we could end up with
simple tests that do not meet our needs.

\subsection{Options}

\subsubsection{Standard 'testing' library}

The simplest and most lightweight option is the standard 'testing' library. This
can be expanded with the additional 'testify' library, which adds functionality
for mocking, assertions, HTTP protocol, and basic functions.

\subsubsection{GoConvey}

GoConvey is a testing framework that allows you to track your test status with a
generated web UI. The tests can run automatically every time you save a .go
file. GoConvey also generates an html test coverage report that allows you to
review where your tests are falling short.

\subsubsection{Ginkgo}

GinkGo is a testing framework that allows you to write specifications for your
tests. It is lighter-weight than GoConvey and works primarily from the command
line. GinkGo takes a black box approach to testing.

\subsection{Goals for use in design}

The goal of the testing framework is to continuously verify our solution.
Testing is important for any software, but it is particularly important in cloud
orchestration networking. Our solution must be robust, and that can only be
verified through rigorous testing.

\subsection{Criteria being evaluated}

The two important criteria when selecting a testing framework is the
capabilities of the framework itself and the complexity of the framework. On one
hand we want the tests to be powerful and support important features such as
mocking and assertion. On the other hand we do not want the test framework to be
so complicated that it is difficult to write tests.

\subsubsection{Capability}

The most important aspect of the testing framework is its ability to perform
mocking. This is essential in unit testing. All three of the test frameworks
allow the programmer to perform mocking.

Another important capability is assertion testing. Once again, all three support
assertion tests.

A third important capability is randomization in testing. This is the best way
to ensure corner cases are hit. This aspect, however, is provided by the Go
standard library and therefore does not factor into this analysis.

One area where GoConvey shines is in its ability to perform testing analysis and
output an easy-to-use web user interface. Ginkgo also provides some extra
functionality related to black box testing.

\subsubsection{Complexity}

Of the three frameworks, the testing package is by far the simplest. Since it
exists in the standard library, there is no overhead of installation or setup to
get started writing tests~\cite{testing}.

Ginkgo is slightly more complicated to setup, since it is necessary to install
and run a few Ginkgo-specific commands before ready to start writing tests. Once
everything is ready, you can write tests, but must use Ginkgo-specific keywords
and tests to utilize its full potential~\cite{ginkgo}.

The most complex framework is the GoConvey suite. This is no surprise,
considering how powerful it is. GoConvey requires the programmer to view the
test results in a browser, as well~\cite{goconvey}. This is difficult for our
purposes, since we will be doing much of our development on remote machines via
ssh, and will not have access to an X server to view the results.

\subsection{Direct Comparison}

\begin{center}
	\begin{tabular}{| l | l | l |}
		\hline
		Framework & Capability & Complexity
		\\ \hline
		testing  & 3 & 1  \\ \hline
		GinkGo   & 2 & 2  \\ \hline
	Fwd: EECS Winter Term Registration PINS	GoConvey & 1 & 3  \\ \hline
	\end{tabular}
\end{center}

\subsection{Selection}
Although the direct comparison reveals that all three are equally averaged to
second place overall, the decision here is weighted towards the lowest in
complexity. Our solution will be complex and difficult to implement, we do not
want to have to worry about learning how to use a complicate testing framework
on top of everything else. The standard 'testing' package will be used for
functional and unit testing of our solution.

% Cody
\section{Packet Level Protocols}
One of the main components of our system is deciding which protocol will be
used to move data from one node to the next. Ciao provides its own data
transfer protocol using SSNTP. Comparing how SSNTP works in general to other
data transfer formats will provide insight into which protocol should be used.

\subsection{Options}

\subsubsection{SSNTP}
Simple and Secure Node Transfer Protocol is Intel's solution for the transfer
of data inside of Ciao networks. It is based on Transport Layer Security (TLS),
the defacto standard for secure data transfer over the Internet. Part of what
sets Ciao apart from the competition is its simplicity, as well as concise
message format.\cite{ssntp}

\subsubsection{TLS}
Transport Layer Security, or TLS, is the contemporary standard for secure data
transfer across the Internet. It was built as an improvement upon the Secure
Socket Layer protocol. It has great appeal as it is widely utilized, modern,
and well studied.\cite{tls}

\subsubsection{SSL}
Secure Socket Layer, or SSL, was the first version of what eventually became
TLS following its third major revision. Originally utilized in Netscape, it
wasn't widely utilized until it's third major revision. Secure Socket Layer
encrypts at the application layer, allowing broad general use. While being
somewhat older than the other protocols on the list, it is well understood and
the security has been well proven.\cite{ssl}

\subsection{Goals for use in design}
The primary goal of the selected protocol is fast, stable, secure, and
scalable communication between compute nodes and the orchestration node in
Ciao. These are simple, but critical goals for the project.

\subsection{Criteria being evaluated}
The criteria for each protocol will be their security capabilities, protocol
overhead, and ease of use. While stability is a concern, each protocol has
shown stability through implementation in other applications many times over.
This will be less of a focus for evaluation purposes.

\subsubsection{Speed}
Speed is a major consideration when working with a software defined network.
Our final selection for a protocol needs to be fast. Any major delays in
communication due to encryption or protocol overhead is a concern. While each
implementation of the protocol will have its pros and cons, here the focus
will be on application overhead to keep the metric in measurable territory.

SSL has two major components, the protocol, and the handshake protocol. The
handshake protocol is important as it ensures the overall security and
authenticity of the communication between point A and point B.
~\cite{topdown-ssl}

%Diagram of SSL handshake here
\begin{figure}[H]
	\begin{center}
		\makebox[\textwidth]{\includegraphics[scale=.35]{ssl-diag.eps}}
		\caption{Simple SSL and TLS Handshake\cite{ibm-diagram}}
	\end{center}
\end{figure}

The SSL/TLS handshakes are identical. As far as overhead the two protocols
are very similar. The primary difference between them is their security levels,
which will be discussed in the following section.

The SSNTP equivalent of a handshake is called a SSNTP Connection. There is a
fundamental difference that needs to be noted between SSNTP and the other two
options. The difference is that the computers running SSNTP client software
only have to do an authentication handshake, or SNTP Connection in this case,
once. Once the client knows which server it is talking to, all connections
no longer require a handshake step. This is a massive drop in needed overhead.
\cite{ssntp} Once the handshake is established, the client communicates with
the server in an asynchronous fashion as needed.

\subsubsection{Security}
Security is important in choosing a communication protocol. If it wasn't, we
could just use TCP, the protocol that all of these security protocols
encapsulate.

SSL is unfortunately at the bottom of the list as far as the
protocols listed here are concerned. Has a few vulnerabilities that have been
found in the decade or so. While some of these are less of an issue, one attack
in particular called POODLE has caused several major groups to call for SSL 3.0
to be deprecated.\cite{poodle} While calling into question consideration for
using this protocol on this system, it is still better than not having any
security or encryption at all.

TLS is much better on this front as it is continually being updated. The latest
release, version 1.2, uses AES, RC4, and a few other modern encryption ciphers.
\cite{tls} Which encryption cipher is used is negotiated between the host and
the client before communication begins.

SSNTP uses the TLS encryption protocols. On this front, it is equal to TLS.

\subsubsection{Accessibility}
All of the above protocols are well documented and easy to implement. In the
scope of the project, however, SSNTP would be easier to use because other
components of the system already use it. For that reason alone, it is simpler
to get working for the project.

\subsection{Direct Comparison}
Here is a side by side comparison of the protocols in the form of a table:

\begin{center}
	\begin{tabular}{| l | l | l | l |}
		\hline
		Protocol & Speed & Security & Accessibility \\ \hline
		SSNTP & 1 & 1 & 1 \\ \hline
		SSL & 2 & 3 & 2 \\ \hline
		TLS & 2 & 1 & 2 \\ \hline
	\end{tabular}
\end{center}

\subsection{Selection}
For our project, the technology for protocols will be SSNTP. It does what SSL
and TLS do equally security wise, but is much more light weight and is more
accessible in the context of the project.

%----------------------

\section{nvGRE and VxLAN Switches}

\subsection{Options}

\subsubsection{nvGRE}

\subsubsection{VxLAN}

\subsubsection{}

\subsection{Goals for use in design}

\subsection{Criteria being evaluated}

\subsubsection{}

\subsubsection{}

\subsubsection{}

\subsubsection{}

\subsection{Direct Comparison}

\subsection{Selection}

%----------------------

\section{GRE/Linux Bridges}

\subsection{Options}

\subsubsection{Linux Bridges}

\subsubsection{}

\subsubsection{}

\subsection{Goals for use in design}

\subsection{Criteria being evaluated}

\subsubsection{}

\subsubsection{}

\subsubsection{}

\subsubsection{}

\subsection{Direct Comparison}

\subsection{Selection}

%-----------------------------------------------
% CNCI OVS Implementation
% Compute Node OVS Implementation
% Performance Testing Framework  

\section{CNCI Implementation}

\section{Compute Node Implementation}

\section{Performance Testing Framework}
One of our project requirements is to conduct network performance testing on our implementation.
The purpose of testing network performance is to determine which tunneling protocols to use, 
and how our Open vSwitch implementation compares to the initial implementation.
The two metrics we want to measure are latency and throughput.
Latency is how long it takes data to travel between hosts on a network~\cite{topdown-ssl}.
Throughput is how much data can be transferred between two hosts on a network in a fixed amount of time~\cite{topdown-ssl}.

\subsection{Options}

\subsubsection{iPerf3}
iPerf3 is an open source tool for measuring network throughput~\cite{iperf}.
It runs in a client server configuration on two hosts and measures throughput between the client and server.
It can be configured to use random data, or to send a file across the network.
It supports both TCP and UDP, as well as IPv4 and IPv6.
It can be bound to specific network inferfaces on devices with more than one network interface.
It can be configured to produce output in JSON format. 
This is an advantage because it is human readable, and easily parsible with many programming languages.
It does not measure latency. 
If we use iPerf3 to measure network throughput we will need to use another tool to measure network latencty.
Below is an example from the iPerf3 documentation of running it from the command line to measure the latency between hosts~\cite{iperf}.
\begin{lstlisting}[caption = Sample iPerf 3 usage]
node2> iperf -s
------------------------------------------------------------
Server listening on TCP port 5001
TCP window size: 60.0 KByte (default)
------------------------------------------------------------
[  4] local <IP Addr node2> port 5001 connected with <IP Addr node1> port 2357
[ ID] Interval       Transfer     Bandwidth
[  4]  0.0-10.1 sec   6.5 MBytes   5.2 Mbits/sec

node1> iperf -c node2
------------------------------------------------------------
Client connecting to node1, TCP port 5001
TCP window size: 59.9 KByte (default)
------------------------------------------------------------
[  3] local <IP Addr node1> port 2357 connected with <IP Addr node2> port 5001
[ ID] Interval       Transfer     Bandwidth
[  3]  0.0-10.0 sec   6.5 MBytes   5.2 Mbits/sec
\end{lstlisting}


\subsubsection{Wireshark}
Wireshark is a network protocol analyzer that can be used to measure many network statistics including latency and throughput~\cite{wireshark}. 
It has a command line interface called tshark.
It supports saving network traffic to a capture file that can be analyzed at a later date.
Wireshark only analyzes network traffic, it does not generate it.
We would need to use Wireshark in combination with one of their recommended traffic generator tools~\cite{wireshark-tools}.
Wireshark is very complex and has a lot of features we do not require for our use case.
If we take the capture file it generates and open it with the GUI version of Wireshark we can generate graphs without feeding the data into another application.

\subsubsection{Ping}
Ping is a command line tool that can be used to measure the latency between two hosts~\cite{ping}.
It is a standard networking tool that is well tested and simple to use.
The output is human readable, but not very machine readable. 
We would need to parse the output into a more computer friendly format before graphing it.
It does not support throughput statistics so we would need to use another tool to calculate throughput.
It can be configured to send a specific number of packets and will return the latency for each packet sent, as well as the minimum, average and maximum latency for the packets sent.
\begin{lstlisting}[caption = Example ping usage]
[smithgar@flip3:~ ] \$ ping -c 5 oregonstate.edu
PING oregonstate.edu (54.244.95.93) 56(84) bytes of data.
64 bytes from ec2-54-244-95-93.us-west-2.compute.amazonaws.com (54.244.95.93): icmp_seq=1 ttl=42 time=10.6 ms
64 bytes from ec2-54-244-95-93.us-west-2.compute.amazonaws.com (54.244.95.93): icmp_seq=2 ttl=42 time=10.6 ms
64 bytes from ec2-54-244-95-93.us-west-2.compute.amazonaws.com (54.244.95.93): icmp_seq=3 ttl=42 time=12.8 ms
64 bytes from ec2-54-244-95-93.us-west-2.compute.amazonaws.com (54.244.95.93): icmp_seq=4 ttl=42 time=10.6 ms
64 bytes from ec2-54-244-95-93.us-west-2.compute.amazonaws.com (54.244.95.93): icmp_seq=5 ttl=42 time=11.1 ms

--- oregonstate.edu ping statistics ---
5 packets transmitted, 5 received, 0\% packet loss, time 4005ms
rtt min/avg/max/mdev = 10.628/11.204/12.877/0.871 ms
\end{lstlisting}

\subsubsection{Netcat}
Netcat is a tool that can be used to read and write data across networks from the command line~\cite{netcat}.
When combined with timing software it can be used to calculate throughput.
It is a standard networking utility and is well tested.
The downsides to using Netcat are that you have to generate input using a tool such as dd.
\begin{lstlisting}[caption = Caclulating throughput with netcat and dd~\cite{nc-example}]
server\$: nc -v -l 2222 > /dev/null
client\$: dd if=/dev/zero bs=1024K count=512 | nc -v \$IP_OF_SERVER 2222
Result from dd:
536870912 bytes (537 MB) copied, 4.87526 s, 117 MB/s
\end{lstlisting}

\subsection{Tool requirements}
The tool must work on Clear Linux which is the Linux distribution we are running Ciao on.
It must allow us to measure network latency and throughput. 
It must have a command line interface.
We must be able to capture the output and easily translate it into useful data. 
We should be able to graph the results. 
If one tool does not meet all of our needs we can use a combination. 

\subsection{Tool comparison}

\begin{center}
	\begin{tabular}{| l | l | l | l | l |}
		\hline
		Name & Latency Measurement & Throughput Measurement & Output type & Standalone \\ \hline
		iPerf3 & No & Yes & Human Readable or JSON & Yes \\ \hline
		Wireshark & Yes & Yes & Capture File & No \\ \hline
		Ping & Yes & No & Human readable text & Yes \\ \hline
                Netcat & No & Yes & Human readable text & No \\ \hline
	\end{tabular}
\end{center}

\subsection{Selection}
Ping and iPerf3 are the two tools I chose for gathering network latency and throughput statistics.
Ping is simple to use, gives us the information we need and does not require any special configuration or other tools. While it only allows us to calculate latency, it is the best choice for us for that purpose.
Wireshark requires more configuration than Ping, and we would need to set up a tool to generate traffic.
I chose iPerf3 because it handles measuring throughput without any special configuration or other tools.
It also allows generating output in JSON format which allows us to parse the results with many different programming languages. 
While it does not support calculating latency, it is our best choice for calculating throughput.
This makes it easy to graph and analyze the results.
Wireshark offers many of the same features as iPerf3 but it requires more set up and configuration, and does not output its results in as universal of a format. 
We would also need to set up a tool to generate network traffic.
Netcat must be used in combination with other utilities and does not output its results in as nice of a format as iPerf3.


\section{Conclusion}

We explored nine components of our system and three technologies of each,
resulting in an overview and comparison of twenty-seven technologies. We settled
on one or more technologies per comparison. A summary of the selected
technologies are listed below.

\begin{enumerate}
	\item Programming Language - Golang
	\item Logging Library - glog library
	\item Functional Testing Framework - logging library
	\item Packet Level Protocols - SSNTP
	\item Switch Implementation -
	\item Bridge Implementation -
	\item CNCI Implementation -
	\item Compute Node Implementation -
	\item Performance Testing Framework -
\end{enumerate}

These selections were made based on research, and not trial implementation.
These selections may change if blocking issues are discovered in the future.

\bibliographystyle{IEEEtran}
\bibliography{tech}

\end{document}
